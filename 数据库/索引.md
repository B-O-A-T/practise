-   [一条SQL涉及到的数据库流程概述](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#一条sql涉及到的数据库流程概述)
-   database learning
    -   [sql rewrite](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#sql-rewrite)
    -   learned index
        -   [1. the case for learned index structure](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#1-the-case-for-learned-index-structure)
    -   optimizer
        -   [1. cardinality](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#1-cardinality)
        -   [计划选择](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#计划选择)
        -   [3. pure learning model: neo](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#3-pure-learning-model-neo)
    -   [AQP](https://note.youdao.com/md/preview.html?file=%2Fyws%2Fapi%2Fpersonal%2Ffile%2FWEB56d9a1996016e7a11e59897f06fb6db5%3Fmethod%3Ddownload%26read%3Dtrue%26shareKey%3Deb6f78b577c6feb07c57b23211ce793e#aqp)



# 一条SQL涉及到的数据库流程概述

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1ggxso8nn9ij30ie0bgq8m.jpg?ynotemdtimestamp=1596013122314)

一共三块内容：`客户端`、`server层`、`储存引擎`

从上图可以看出一条sql语句从客户端到结束的流程

1.  客户端输入sql

>   高效的sql书写逻辑将很大程度影响查询效率

1.  查询缓存

>   mysql的从8.0起取消了

>   只要有对一个表的更新，这个表上所有的查询缓存都会被清空

>   SQL任何字符上的不同,如空格,注释,都会导致缓存不命中

1.  解析器(语法)和预处理器对语法树的分配

```
#解析器
You have an error in your SQL syntax
#预处理器
Unknown column xxx in ‘where clause’
```

1.  查询优化器生成查询树

优化器可以从数据字典中获取许多统计信息，例如表中的行数、表中的每个列的分布情况等。优化器优化器可以考虑百种不同的执行计划，而程序员一般只能考虑有限的几种可能；可以根据这些信息选择有效的执行计划，而用户程序则难以获得这些信息；总之优化器是对语法分析树的形态进行修改，把语法分析树变为查询树，确定执行

```
select t1.*
from Table1 t1
inner join Table2 t2
on t1.CommonID = t2.CommonID
select t1.*
from Table1 t1
STRAIGHT_JOIN Table2 t2
on t1.CommonID = t2.CommonID
```

1.  执行器 根据执行计划来进行执行查询,根据指令，逐条调用底层存储引擎"MySQL定义了一系列抽象存储引擎API，以支持插件式存储引擎架构。Mysql实现了一个抽象接口层，叫做 handler(sql/handler.h)，其中定义了接口函数，比如：ha_open, ha_index_end, ha_create等等，存储引擎需要实现这些接口才能被系统使用。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh0uua4jhvj30lt0biq63.jpg?ynotemdtimestamp=1596013122314)

1.  Parser:实现一般不自己写轮子，大多数语言都有成熟的编译器库在，如javacc就有实现了开源的SQLparser，生成如下的语法树

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh0umb8e66j30rk0gkwif.jpg?ynotemdtimestamp=1596013122314)

1.  Binder:在上一步中输入错误的sql语法，比如从一张不存在的数据表中查数据，会出现什么问题？没有任何问题，这一步由binding解决，最后生成了Bounded AST
2.  Optimizer:给定了语法树，优化器会先生成一个逻辑执行树 (logical operator tree),然后根据cost model或自定义规则将logical operator替换成相应的physical operator
3.  Executor:根据上一步得到的最优执行计划，执行器要做的就是加载相应操作符的代码，然后依次执行这些代码。 至此，一个完整的由输入 SQL 语句开始，到输出结果集的生命周期完整结束。梳理一下：

1）用户输入 SQL 语句 -> 编译器 -> 抽象语法树

2）抽象语法树 -> 绑定器 -> 绑定语义的语法树

3）绑定语义的语法树 -> 优化器 -> 物理执行计划

4）物理执行计划 -> 执行器 -> 运行执行计划，得到结果集，返回给用户

不过这个流程实际上只涉及了server层，执行器调用的下层引擎主要了解两块内容，存储和索引

>   回头要补充下优化器中在选择计划时的order joining的东西

-   存储

>   一个数据库存的是什么呢？这里简单介绍一下关系模型 ( relational model )。关系模型由 Ted Codd1970 年提出，关系模型定义了所有的数据都是以元组 (tuple) 的形式存在，每个元组定义了多个属性 (attribute) 的键值对，多个含有相同属性的元组排列在一起就形成了一个关系 (relation)。元组，属性和关系对应到数据库中的概念就是行 (row)，列 (column), 和表 (table)。一个表定义了多个 column，每个 column 有一个 type，每个 row 对应于每一个 column 都有一个取值 (取值满足 type 的定义)，每个表又由多个 row 构成。不同的数据库虽然有库（database)，schema 或者命名空间 (namespace) 等不同级别的逻辑抽象，但是表却是每个关系型数据库最基本的存储对象。

假设我们现在手头只有一张csv表

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1b4if72oj30ka03ugnl.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1b6jx868j30k703dwg9.jpg?ynotemdtimestamp=1596013122314)

数据缺少一些描述性信息，比如Header, 类型定义，还可以进一步改进，分离meta data 单独存表

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1b9bs1grj308k0cemyd.jpg?ynotemdtimestamp=1596013122314)

在这种升级的存储方式中，对应的对于attribute level的操作可以采用标注思想，比如删除某列，只需要在meta data的文件中标注删除而不需要修改原表

接下利用这种思想又可以继续升级原来的存储方式，首先对于每一个数据行(row)单独存个csv的slot_table

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1b4if72oj30ka03ugnl.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bgw42dej304k082dft.jpg?ynotemdtimestamp=1596013122314)

这种方式可以良好支持update操作，Delete第二行，slot_table直接标为D(delete)，数据表不用改 修改第一行的值，将第一行标为D,数据表新增一行

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bgpfkjrj3058095t8q.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bl72tw4j30ka04idi3.jpg?ynotemdtimestamp=1596013122314)

上面还是不够简洁，没有实现slot_table的append only,不能很好地track history， 可以把标注信息也以 append only 的形式添加到 slot_table 中，比如上述的删除和修改操作完成后，slot_table 如下：

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bsmjlqvj305f0bc0st.jpg?ynotemdtimestamp=1596013122314)

对于数据的增删改，我们已经可以对数据文件和 slot_table 都实现 append_only。

对于一个数据表，每次操作都会添加新信息，久而久之，数据文件越来越大，而且无效的行越来越多，很浪费空间。数据库支持 vacuum 操作 (或者叫 compact)，读取数据文件和 slot_table，然后根据标注把有效的数据行写回新的文件。比如，对我们的示例进行 vacuum 操作，新的数据文件和 slot_table 如下所示:

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bwfatpij30k104ftaq.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1bwkgvcmj304w072dfs.jpg?ynotemdtimestamp=1596013122314)

还可以继续升级，引入列存概念

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1c09jd7lj30lg0dtju5.jpg?ynotemdtimestamp=1596013122314)

OLAP中经常需要查询某表的几列，这时候可以对每一列进行列存，相对应的列存，就是指把一个表的每个属性， 单独存在一个数据文件中。还是沿用上面 titanic 的例子，我们会有单独的数据文件 (还有 slot_table 文件) 来存储姓名，船票价格，登船码头，等等。在读取的时候，根据查询语句需求，需要用到哪个属性就读取哪个属性的数据文件。按照前面的例子，我们只需要读取原来的 3 个属性的数据文件，读取速度自然就提高了。

>   除了可以避免读取不必要的数据，因为每一列的类型是相同的，比如都是整形或者是字符串。在存储同类型的数据时，压缩算法能够更有效地进行压缩,需要时再查相关内容

-   索引

索引与存储息息相着

列存的实现，使得我们不用读取无用列的数据，但针对某些点查询的语句 (point query)，

```
 SELECT * FROM titanic_survivor WHERE age = 10;
```

点查询同时涉及了行列，加快的关键就索引

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1b6jx868j30k703dwg9.jpg?ynotemdtimestamp=1596013122314)

先考虑hash index,针对如上的数据用age建索引，(k,v)=(value,list(row))

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1tg2nf8cj30440610st.jpg?ynotemdtimestamp=1596013122314)

但对于range search的情况，比如当22<=age<=38,这里当然可以hash三次

要是age>=2呢的话，在这种小数据量还是没问题

但可以继续升级，也就是用b或b+树，对应的只是将key排好序,再利用二分思想

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1tlqehj3j305j06bjrg.jpg?ynotemdtimestamp=1596013122314)

为什么避免节点分离和加锁这些情况还可以用跳表 ![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1uetq0c6j30k507jjt2.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1tte1p1aj30l9077gna.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1ufehl85j30jx05omyr.jpg?ynotemdtimestamp=1596013122314)

为了对基数很小的列进行定位，可以用位图索引 ![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1uhs1yzyj307d0380su.jpg?ynotemdtimestamp=1596013122314)

```
SELECT * FROM titanic_survivor WHERE sex = 'female' AND cabin = 'A'
```

优点：存储量小

缺点： 不适用高并发

注意：

1.  索引能够提升效率，但这取决于查询语句以及数据的分布
2.  是否决定使用索引，是由数据库的优化器决定

# database learning

## sql rewrite

主要与自然语言类似,一条 SQL往往有很多种优化方案，而人的认知往往会受到当前 SQL结构的影响，而不 能找到最优的 SQL 写法。内部 SQL 重写则在优化器内完成。重写器会对解析出来的 SQL 树进行修改和替换，如用已有的物化视图代替原始表；去掉多余的连接操作。传统重写器只会做节点级别的修改，即去除无用操作，替换已有的临时表。

## learned index

### 1. the case for learned index structure

将传统的数据库索引(Index)视为一种模型(Model),比如：

-   B-Tree索引B-Tree索引模型将一个Key映射到一个排序数组中的某位置所对应的记录
-   Hash索引Hash索引模型将一个Key映射到一个无序数组中的某位置所对应的记录
-   Bitmap索引Bitmap索引模型用来判断一条记录是否存在

核心思想： 学习数据的分布来优化索引，用神经网络模拟函数，实现类似value=hash(key)的效果

现有的索引结构中，B树对于范围查询无疑是最佳的，哈希表对于kv查询是最合适的，而布隆过滤器更多用于查询 key是否存在于某个数据集中

这些传统索引却存在一个最显著的问题：它们没有考虑数据的分布特点，往往预先假设了最差的数据分布，从而期望索引具备更高的通用性。因此，这些索引往往会导致大量的存储空间浪费，而且性能无法达到极致。

对于一个小数据集（ 1-100M），那么这时候如果使用 B 树其实不是最合理的，因为 key 值本身就可以作为偏移量使用，如果使用 B 树的话，无疑是把 O(1) 的时间复杂度变成了O(logn)

-   btree index

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh10iks3hjj30xe0eg0zo.jpg?ynotemdtimestamp=1596013122314)B-Tree中通常按照Page来组织数据，每一个Page对应B-Tree中的一个节点。基于一个Key进行查询时，事实上是先通过非叶子节点的索引信息，查找到一个目标Page，可以将这个过程理解为：基于B-Tree Index模型，对一个给定Key值所在的数据位置做了”预测”。Learned Index要对B-Tree Index所做的改造，希望能够做到更快速的预测，误差率要在可控的范围内：

Learned Index是完全可以实现100%accuracy的，只需要在predict的position向左或向右scan即可（或者二分查找），直到找到真正的tuple

-   Hash索引(Point Index)

对于Hash索引而言，基于Key的查询，在性能上已经是极致了，因此，Learned Index已经难以进行突破。但现有的Hash索引存在一个显著的问题：基于通用数据分布设计的Hash Function，难免会带来明显的键冲突问题，当两个键冲突以后，通常基于一个linked-list或secondary probing来处理重复的记录，无论哪种方式，都会导致在存储空间占用上带来一些浪费。

Learned Index期望对数据的分布进行学习以后，能够提供一种更佳的模型(即寻找一种更佳的Hash Function)，尽可能的降低键冲突 ![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh11flnr0fj313y0jm42j.jpg?ynotemdtimestamp=1596013122314)

-   Bloom Filter索引(Existence Index) ![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh11lxgbitj311u09emz2.jpg?ynotemdtimestamp=1596013122314)

当判断一个Key是否存在于这一个集合中时，也是先利用3个Hash函数对Key值计算得到3个Hash值，而后判断这3个Hash值所对应的位是否为1，如果都为1，则可断定Key值是可能存在的,Hash值存在一定概率的键值冲突 。因此，这3个位有可能是被别的Key的Hash值改为1的。这就是Bloom Filter所谓的“误判”。但当Bloom Filter判定一个元素不存在时，该结果却是确定可信的。 与前面提及的问题类似：传统的Bloom Filter的实现，并不会参考实际的数据分布特点，更不会考虑有效Key和无效Key之间的区别。

利用Bloom Filter索引判断一个Key值存在与否（或者说判断一个Key是否为有效Key），也可以理解为一个二值分类问题。

## optimizer

### 1. cardinality

目前已有的传统数据库基数估计技术分为直方 图（histogram），数据画像（sketching）和采样 （sampling）三类方法

由于进行计划选择时是基于cost model,cost model又很大程序上决定于cardinality，传统的数据库中对于基数估计误差比较大，提高cardinality estimation的准确率来选择出更优的plan

>   具体看cardinality 与selectivity的概念，后者决定了一个索引的高效性，从而在优先阶段确定是否使用这个索引，具体可以参考https://www.cnblogs.com/25-lH/p/10973309.html

### 计划选择

计划选择：对于一个 SQL 查询语句,数据库的计划选择器会生成相应的连接计划。不同的查询计划对于查询效率有非常大的影响。而且它的状态空间的大小关于表的连接数量是指数级的，找到最优查询计划是一个 NP-hard 问题

现在的数据库里用的是启发式算法

>   启发式算法（Heuristic Algorithm）有不同的定义：一种定义为，一个基于直观或经验的构造的算法，对优化问题的实例能给出可接受的计算成本（计算时间、占用空间等）内，给出一个近似最优解

任何empirical的算法有是有可能用deep learning来学习的

### 3. pure learning model: neo

Neo 全称 Neural Optimizer，是一个基于深度神经网络设计的优化方案。NEO 使用 Postgres 的优化器作为 bootstrap，在此基础上利用强化学习+DNN模型做迭代改进，能获得比肩商业数据库的性能。

下图是 Neo 的系统结构，它替换了 DBMS 中的优化器部分。

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1t7g3zb0j30ph050jst.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1t96hlixj30f60c2dhd.jpg?ynotemdtimestamp=1596013122314) 主要流程如下：

1.  使用一个“弱”的优化器（比如 PG 的优化器）生成一个初始执行计划，称为 bootstrap
2.  Experience 表示一个（执行计划 -> latency）的集合，这是训练样本
3.  Featurizer 抽取两种类型的特征：Query-level 特征、(Partial) Plan-level 特征
4.  用抽取到的特征训练模型 Value Model，建立 plan -> latency 的预测模型
5.  在这个模型上做 Plan Search，这里用的是简单的贪心搜索，选出一个执行计划

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1z54mj92j30nw092myw.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gh1zcdtekkj30ms05zdh0.jpg?ynotemdtimestamp=1596013122314)

## AQP

1.  传统近似算法
2.  使用贪心方法的近似算法，用于解决独立集、旅行商问题等；
3.  序贯算法（Sequential Algorithm）的近似算法，目前已用于解决装箱、图着色问题等；
4.  用局部搜索（Local Search）的近似算法，目前已用于解决最大割、旅行商问题等；
5.  使用线性规划的近似算法，目前已用于解决最大割、顶点覆盖问题等；
6.  使用动态规划的近似算法， 目前已用于解决装箱、背包问题等；
7.  使用随机化算法的近似算法，目前已用于解决斯坦纳树（Steiner Tree）、最大割（Maximum Cut）

1.  AQP

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gglp7cx17gj31060lkan7.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gglp6p29cej312y0m6amo.jpg?ynotemdtimestamp=1596013122314)

![img](https://tva1.sinaimg.cn/large/007S8ZIlgy1gglpatn1yuj30ti0h4q99.jpg?ynotemdtimestamp=1596013122314)

1.  单表聚集： 重点放在如何改进在线聚集过程中的采样方法和误差估计方法上。对于采样方 法的研究历史悠久且种类繁多，而误差估计主要有 Bootstrap和基于中心极限定理（CLT）

    早期用的是假设均匀分布下的随机均匀采样，后期针对稀疏数据问题，提出了分层抽样（stratified sampling）的采样方法

    Bootstrap 方法主要有两个缺陷[20]：一是当聚集函数对稀有元组敏感（如MAX），或样本集 S 的样本容量太小，不足以支持足够质量的重采样时，Bootstrap 对采样分 布的估计效果可能很差；二是 Bootstrap 对采样分布的精确度随着重采样次数增加而增长， 在多数情况下，可能需要进行大量重采样，时间成本较高。

    Bootstrap 方法与基于中心极限定理的方法[21]相比，前者通用性更好，但计算成本相对 较高；后者有效性很强，但仅适用于简单的聚集查询[22]。

参考资料：http://mashuai.buaa.edu.cn/pubs/bigdataApprox.pdf