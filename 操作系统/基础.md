### 1、进程与线程的本质区别，以及各自的使用场景

程序不能单独进行，只有将程序装载到内存中，系统为它分配资源才能运行，而这种执行的程序就称之为进程。程序和进程的区别就在于：程序是指令的集合，它是进程运行的静态描述文件；进程是程序一次执行活动，属于动态概念。程序是资源分配的基本单位

线程是CPU使用的基本单元，它由线程ID、程序计数器、寄存器集合和栈组成。它与属于统一进程的其他线程共享代码段、数据段和其他操作系统资源。多线程编程优点：响应度高，资源共享，经济，多处理器体系结构的利用。

区别：

-   进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行**资源分配和调度的一个独立单位**。
-   线程是进程的一个实体, 是**CPU调度和分派的基本单位**,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如**程序计数器,一组寄存器和栈**),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。
-   一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行。
-   线程缺乏访问控制，进程中的一个线程出错，会终止掉整个进程。
-   切换的效率，复杂度也不同。

### 2、进程状态

新的：进程在创建时需要申请一个空白PCB，向其中**填写控制和管理进程的信息，完成资源分配**。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态

运行：进程处于就绪状态**被调度**后，进程进入执行状态

等待：正在执行的进程由于某些事件（**I/O请求，申请缓存区失败**）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用

就绪：进程已经准备好，已**分配到所需资源**，只要分配到CPU就能够立即运行

终止：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行

一次只有一个进程可在一个处理器上运行，但是多个进程可处于就绪或等待状态。

如果进程运行**时间片使用完**也会进入就绪状态。 
另外为用户观察需要，进程还有挂起和激活两种操作。挂起后进程处于静止状态进程不再被系统调用，对应操作是激活操作。

![image-20200728192537841](C:\Users\Dase\AppData\Roaming\Typora\typora-user-images\image-20200728192537841.png)

### 3、 进程调度算法的特点以及使用场景。

先来先服务调度算法（first-come，first-served）：总是把当前处于就绪队列之首的那个进程调度到运行状态。

-   用FIFO队列来容易地实现
-   非抢占 优点：有利于**长作业**以及CPU繁忙的作业，缺点：不利于短作业以及I/O繁忙的作业

最短作业优点调度：对预计执行时间短的作业（进程）优先分派处理机.通常后来的短作业不抢先正在执行的作业。

优先级调度算法，在进程等待队列中选择优先级最高的来执行。常被用于**批处理系统**中，还可用于**实时系统**中。

-   可以是抢占的，也可以是非抢占的
-   存在无穷阻塞或饥饿。解决方法老化

轮转法调度（round-robin）：让每个进程在就绪队列中的等待时间与享受服务的时间成正比例。属于抢占式调度。优点是兼顾长短作业；缺点是平均等待时间较长，上下文切换较费时。适用于**分时系统**。

**多级反馈队列算法**：设置多个就绪队列，分别赋予不同的优先级。

**高响应比优先调度算法**：根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是**计算响应比开销大**，适用于**批处理系统**。

### 4、线程实现的方式

线程的实现可分为两大类，用户级线程（user-levelthread，ULT）和内核级线程（kernel-levelthread，KLT）。后者又称为内核支持的线程或轻量级进程。

**（1）用户级线程**

在一个纯粹的用户级线程软件中，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。

使用用户级线程而不是内核级线程的优点有：

-   线程切换不需要内核态特权，进程并不需要为了线程管理而切换到内核态
-   可以为应用程序量身定做调度算法而不扰乱底层的操作系统调度程序
-   用户级线程可以在任何操作系统中运行，不需要对底层内核进行修改以支持用户级线程

相比内核级线程，用户级线程有两个明显的缺点：

-   许多系统调用都会引起阻塞，当**用户级线程执行一个系统调用**时，不仅这个线程会被阻塞，进程中的所有线程都会被阻塞
-   在纯粹的用户级线程策略中，一个多线程应用程序不能利用多处理技术

**（2）内核级线程**

在一个纯粹的内核级线程软件中，有关线程管理的所有工作都是由内核完成的，应用程序部分没有进行线程管理的代码，只有一个到内核线程设施的应用程序编程接口（API）。

该方法克服了用户级线程方法的两个基本缺陷：内核可以同时把同一个进程的**多个线程调度**到多个处理器中；如果进程中的一个线程被阻塞，内核可以调度同一个进程中的另一个线程。

相比用户级线程它的主要缺点是：用户级线程的线程切换需要少量的机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟。

### 5 、协程的作用

协程是进程和线程的升级版,进程和线程都面临着内核态和用户态的切换问题而耗费许多切换时间,
而协程就是**用户自己控制切换**的时机,不再需要陷入系统的内核态。
协程的**执行效率**非常高。因为子程序切换不是线程切换，而是由程序自身控制。因此，**没有线程切换的开销**，和多线程相比，线程数量越多，相同数量的协程体现出的优势越明显
不需要多线程的锁机制。由于只有一个线程，也不存在同时写变量的冲突，在协程中控制共享资源不需要加锁，只需要判断数据的状态，所以执行效率远高于线程 ，对于多核CPU可以使用多进程+协程来尽可能高效率地利用CPU。

### 6、★★☆ 常见进程同步问题。

**生产者与消费者问题**

问题描述：一组生产者进程和一组消费者进程共享一块初始为空，大小确定的缓冲区，该问题的关键就是要保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中空时消耗数据。常采用[进程间通信](https://zh.wikipedia.org/wiki/进程间通信)的方法解决该问题，

问题分析：生产者与消费者进程对缓冲区的访问是互斥关系，而生产者与消费者本身又存在同步关系，即必须生成之后才能消费。因而对于缓冲区的访问设置一个互斥量，再设置两个信号量一个记录空闲缓冲区单元，一个记录满缓冲区单元来实现生产者与消费者的同步。

**读者与写者问题**

问题描述：有读者与写者两个并发进程共享一个数据，两个或以上的读进程可以访问数据，但是一个写者进程访问数据与其他进程都互斥。

问题分析：读者与写者是互斥关系，写者与写者是互斥关系，读者与读者是同步关系。因而需要一个互斥量实现读与写和写与写互斥，一个读者的访问计数和实现对计数的互斥。

**哲学家就餐问题**

问题描述：一张圆桌上坐着五名哲学家，每两名哲学家之间的桌子摆一根筷子，哲学家只有同时拿起左右两根筷子时才可以用餐，用餐完了筷子放回原处。

问题分析：这里五名哲学家就是五个进程，五根筷子是需要获取的资源。可以定义互斥数组用于表示五根筷子的互斥访问，为了防止哲学家个取一根筷子出现死锁，需要添加一定的限制条件。一种方法是限制仅当哲学家左右筷子均可以用时，才拿起筷子，这里需要一个互斥量来限制获取筷子不会出现竞争。

问题解决：一次仅能一个哲学家拿起筷子，效率比较低。

### 7、★★★ 进程通信方法的特点以及使用场景。

**管道**（包括无名管道和命名管道）、**消息队列**、**信号量**、**共享存储**、**Socket**、**Streams**等。其中 Socket和Streams支持不同主机上的两个进程IPC。

**管道**（包括无名管道和命名管道）、**消息队列**、**信号量**、**共享存储**、**Socket**、**Streams**等。其中 Socket和Streams支持不同主机上的两个进程IPC。

**无名管道：**

-   它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。
-   它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。
-   它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且**只存在于内存中**。

![img](https://uploadfiles.nowcoder.com/images/20190723/220525776_1563877094422_D5F5F7880FBB8E93F8D38A1BD0572E3E)

**FIFO，也称为命名管道**，它是一种文件类型。类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO管道中同时清除数据，并且“先进先出”。

-   FIFO可以在**无关的进程之间**交换数据，与无名管道不同。
-   FIFO有路径名与之相关联，它以一种特殊设备文件形式**存在于文件系统**中。

![img](https://uploadfiles.nowcoder.com/images/20190723/220525776_1563877094473_8FF4DD9120B531B7C63FC0680F96E646)

 **消息队列**：是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。

-   消息队列是**面向记录**的，其中的消息具有特定的格式以及特定的优先级。
-   消息队列**独立**于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。
-   消息队列可以实现**消息的随机查询**,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

**信号量：**是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

-   信号量用于**进程间同步**，若要在进程间传递数据需要结合共享内存。
-   信号量基于操作系统的 **PV 操作**，程序对信号量的操作都是原子操作。
-   每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以**加减任意正整数。**
-   支持**信号量组**。

**共享内存**（Shared Memory）：指两个或多个进程共享一个给定的存储区。

-   共享内存是**最快**的一种 IPC，因为进程是直接对内存进行存取。
-   因为多个进程可以同时操作，所以需要进行**同步**。
-   **信号量+共享内存**通常结合在一起使用，信号量用来同步对共享内存的访问。

总结：

-   管道：速度慢，容量有限，只有父子进程能通讯   
-   FIFO：任何进程间都能通讯，但速度慢   
-   消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题  
-   信号量：不能传递复杂消息，只能用来同步   
-   共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存

### 8、★★★ 死锁必要条件、解决死锁策略，能写出和分析死锁的代码，能说明在数据库管理系统或者 Java 中如何解决死锁。

死锁是指两个或两个以上的进程（线程）在运行过程中因**争夺资源**而造成的一种僵局（Deadly-Embrace) ) ，若无外力作用，这些进程（线程）都将无法向前推进。

互斥条件，不可剥夺条件，请求与保持条件，循环等待条件

处理方法：

-   预防死锁：通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来防止死锁的发生。
-   避免死锁：在资源的动态分配过程中，用某种方法去防止系统进入不安全状态。有序资源分配法，**银行家算法**
-   检测死锁：允许系统在运行过程中发生死锁，但可设置检测机构及时检测死锁的发生，并采取适当措施加以清除。
-   解除死锁：当检测出死锁后，便采取适当措施将进程从死锁状态中解脱出来。

数据库中：常见死锁原因，事务之间对资源访问顺序的交替，并发修改同一记录，索引不当导致的死锁

不等待，全回滚

超时

等待图，判断回路，若存在则有死锁，通常来说InnoDB存储引擎选择回滚undo量最小的事务。深度优先，1.2之后采用非递归的方式

### 9、★★★ 虚拟内存的作用，分页系统实现虚拟内存原理。

虚拟内存是计算机系统内存管理的一种技术。 它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。 目前，大多数操作系统都使用了虚拟内存，如Windows家族的“虚拟内存”；Linux的“交换空间”等。对虚拟内存的定义是基于对地址空间的重定义的，即**把地址空间定义为“连续的虚拟内存地址”**，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。

虚拟内存的实现有以下三种方式： 

-   请求分页存储管理。 
-   请求分段存储管理。 
-   请求段页式存储管理。 

[请求分页系统](http://c.biancheng.net/cpp/html/2613.html)建立在基本分页系统基础之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。

在请求分页系统中，只要求将当前需要的一部分页面装入内存，便可以启动作业运行。在作业执行过程中，当所要访问的页面不在内存时，再通过**调页功能**将其调入，同时还可以通过置换功能将暂时不用的页面**换出到外存**上，以便腾出内存空间。

为了实现请求分页，系统必须提供一定的硬件支持。除了需要一定容量的内存及外存的计算机系统，还需要有**页表机制、缺页中断机构和地址变换机构**。

### 10、★★★ 页面置换算法的原理，特别是 LRU 的实现原理，最好能手写，再说明它在 Redis 等作为缓存置换算法。

-   **最佳置换算法（OPT）**（理想置换算法）：从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。
-   **先进先出置换算法（FIFO）**：是最简单的页面置换算法。这种算法的基本思想是：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大。 
-   **最近最久未使用（LRU）算法**：这种算法的基本思想是：利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为。它认为过去一段时间里不曾被访问过的页面，在最近的将来可能也不会再被访问。所以，这种算法的实质是：当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰。

```C++
// 双端链表结构体
struct DListNode {
  	int key,val;
    DListNode* prev, *next;
    DListNode():key(0), val(0), prev(nullptr), next(nullptr) {}
    DListNode(int _key, int _val) : key(_key), val(_val), prev(nullptr), next(nullptr) {}
};
class LRUCache {
private:
    unordered_map<int, DListNode*> cache;
    DListNode* head, *tail;
    int size, capacity;

public:
    // 构造函数，初始化LRUCache
    LRUCache(int _capacity) {
        head = new DListNode();
        tail = new DListNode();
        head->next = tail;
        tail->prev = head;
        size = 0;
        capacity = _capacity;
    }
    
    int get(int key) {
        // 先判断是否存在
        if (!cache.count(key)) {
            return -1;
        }
        // 如果存在，找到该节点
        DListNode* node = cache[key];
        // 把该节点移到头节点的下一个节点
        moveToHead(node);
        //返回值
        return node->val;
    }
    
    void put(int key, int value) {
		// 先判断是否存在
        if (!cache.count(key)) {
             // 如果不存在，首先新建一个节点
            DListNode *node = new DListNode(key, value);
            // 添加进哈希表
            cache[key] = node;
            // 加入到头节点
            addToHead(node);
            // cache大小加一
            size++;
            // 如果大小大于容量，换出
            if (size > capacity) {
				// 删除最后一个节点，并获取这个节点
                DListNode *removed = removeTail();
                // 删除哈希表中的项
                cache.erase(removed->key);
                // 
                delete removed;
                --size;
            }
        } else {
            DListNode* node = cache[key];
            node->val = value;
            moveToHead(node);
        }
    }
    void addToHead(DListNode* node) {
        cout<<"addToHead"<<node->key<<" "<<node->val<<endl;
		node->prev = head;
        node->next = head->next;
        head->next->prev = node;
        head->next = node;
    }
    
    void removeNode(DListNode* node) {
        cout<<"removeNode"<<node->key<<" "<<node->val<<endl;
		node->prev->next = node->next;
        node->next->prev = node->prev;
        
    }
    
    void moveToHead(DListNode* node) {
        cout<<"moveToHead"<<node->key<<" "<<node->val<<endl;
        removeNode(node);
        addToHead(node);
    }
    
    DListNode* removeTail() {
        
		DListNode* node = tail->prev;
        cout<<"removeTail"<<node->key<<" "<<node->val<<endl;
        removeNode(node);
        return node;
    }
};
```



-   **时钟（CLOCK）算法**: 

-   **最不经常使用算法（LFU）**：选择近期最少访问的页面作为被替换的页面，选择最近时期内使用次数最少的页作为淘汰页。这种算法为每个页保留一个用于记录页被访问次数的计数器，每次选择其访问计数器值最小的页换出。

    

    

### 11、★★★ 比较分页与分段的区别。

-   页是信息的**物理单位**，分页是为了实现离散分配方式，以消减内存的外零头，提高内存的利用率。分页仅仅是由于系统管理的需要而不是用户的需要；段是信息的**逻辑单位**，分段的目的是为了能更好地满足用户的需要
-   页的**大小固定**，由**系统**把逻辑地址划分为页号和页内地址两部分，段的长度却**不固定**，决定于**用户**所编写的程序
-   分页的作业地址空间是一维的，即单一的线性地址空间。 分段的作业地址空间是**二维**的 在标识一个地址时，即需给出段名，又需给出段内地址

### 12、★★★ 分析静态链接的不足，以及动态链接的特点。

**静态链接库的优点** 

-    代码装载速度**快**，执行速度略比动态链接库快； 
-    只需保证在开发者的计算机中有正确的.LIB文件，在以二进制形式发布程序时不需考虑在用户的计算机上.LIB文件是否存在及版本问题，可避免DLL地狱等问题。 

**动态链接库的优点** 

-    更加**节省内存并减少页面交换**；
-    DLL文件与EXE文件**独立**，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了**可维护性和可扩展性**；
-    **不同编程语言**编写的程序只要按照函数调用约定就可以调用同一个DLL函数；
-    适用于**大规模的软件开发**，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试。

**各自不足之处**

-    使用静态链接生成的可执行文件体积**较大**，包含相同的公共代码，造成浪费；
-    使用动态链接库的应用程序不是自完备的，它**依赖的DLL模块也要存在**，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息。而使用运行时动态链接，系统不会终止，但由于DLL中的导出函数不可用，程序会加载失败；速度比静态链接**慢**。当某个模块更新后，如果新模块与旧的模块不兼容，那么那些需要该模块才能运行的软件，统统撕掉。这在早期Windows中很常见。

